---
title: "Capítulo 3. Análisis de ciclos"
author: "Diego Munguía Molina ^[Esta obra está bajo una Licencia Creative Commons Atribución 4.0 Internacional.]"
date: "Agosto, 2017"
institute: "Ingeniería en Computación, TEC"
geometry: margin=1in
header-includes:
    - \usepackage{setspace}
    - \providecommand{\subtitle}[1]{\usepackage{titling} \posttitle{\par\large#1\end{center}}}
    - \usepackage[spanish]{babel}
    - \usepackage[linesnumbered,ruled,vlined,spanish,onelanguage]{algorithm2e}
    - \usepackage{amssymb}
    - \SetKwInput{KwInput}{Entradas}
    - \SetKwInput{KwOutput}{Salidas}
    - \newcommand{\twodots}{\mathrel{{.}\,{.}}\nobreak}
output:
  pdf_document:
    latex_engine: xelatex
---

# Capítulo 3. Análisis de ciclos #

Iniciamos este capítulo recordando algunas de las conclusiones que alcanzamos en los capítulos anteriores. La aplicación del modelo RAM al análisis de consumo de recursos de tiempo y espacio de un algoritmo nos permite determinar funciones específicas $T(n)$ y $S(n)$. Sin embargo, resaltamos que prestaremos especial atención a la tasa de crecimiento de dichas funciones conforme crece el tamaño de la entrada $n$. 

De esta forma, posterior a determinar cuál es la función $T(n)$ o $S(n)$, el siguiente paso en nuestro análisis es identificar el término de mayor crecimiento en su definición, para luego descartar cualquier constante en dicho término, y finalmente categorizar la función en alguna clase $\mathcal{O}$, $\Omega$, o $\Theta$.

Partiendo de estos hechos, podemos determinar también que la repetición es una de las principales fuentes de complejidad de un algoritmo. Por tanto debemos prestar especial atención a los constructos repetitivos implicados en el algoritmo que estemos analizando.

Uno de los errores más comúnes que cometemos al iniciar a estudiar y aplicar el análisis de algoritmos es asumir como regla general que cuando tenemos ciclos anidados, el número de repeticiones del ciclo más interno se multiplica por el número de repeticiones del ciclo que lo contiene. Esto puede ser cierto para algunos casos, más no para todos los casos posibles. En este capítulo estudiaremos algunos ejemplos comúnes de diferentes casos de anidamiento de ciclos y cómo éstos pueden afectar el comportamiento de los algoritmos.

## Ciclos anidados independientes ##

Consideremos en primera instancia el problema de multiplicar matrices cuadradas.

\begin{algorithm}[H]
    \KwInput{Matrices $A$ y $B$ ambas de tamaño $n \times n$}
    \KwOutput{Una matriz $C$ de tamaño $n \times n$ tal que $C = A \cdot B$}
  
    \BlankLine
    \caption{Multiplicación de matrices cuadradas}
    \SetAlgoVlined
    
    $C \leftarrow $ matriz $n \times n$ \\

    \For{$i \in [0 \twodots n[$}{
        \For{$j \in [0 \twodots n[$}{
            \For{$k \in [0 \twodots n[$}{
                $C_{ij} \leftarrow C_{ij} + A_{ik} \cdot B_{kj}$
            }
        }
    }

    \KwRet{$C$}
\end{algorithm}

Analizaremos a continuación la complejidad temporal del algoritmo propuesto para resolver este problema. Notamos que incluye tres ciclos anidados que constituyen su principal fuente de complejidad. Observemos la definición de estos ciclos. 

Podemos determinar de antemano que el ciclo más interno, localizado en la línea 4 y definido en términos de $k$, ejecutará $n$ repeticiones desde $k=0$ hasta $k=(n - 1)$. Las operaciones al interior de este ciclo incluyen asignaciones, accesos a memoria y operaciones aritméticas; no las tomaremos en cuenta ya que sabemos que serán representadas en $T(n)$ como una constante que eventualmente descartaremos.

Nos movemos ahora al siguiente ciclo de adentro hacia afuera. El ciclo de la línea 3 está definido en términos de $j$, y también ejecutará $n$ repeticiones desde $j=0$ hasta $j = (n - 1)$.

Finalmente, el ciclo de la línea 2, definido en términos de $i$ también ejecutará $n$ repeticiones desde $i = 0$ hasta $i = (n - 1)$.

Observamos para el ciclo $k$ en la línea 4, que ni su estado inicial ni su condición de parada dependen en ninguna forma de algún estado que cambie con cada iteración del ciclo $j$. Es decir, el ciclo $k$ es independiente del ciclo $j$, y es por esto que podemos determinar de antemano que ejecutará $n$ repeticiones indistintamente del comportamiento del ciclo $j$. Podemos realizar la misma afirmación para los ciclos $j$ e $i$.

Puesto que los ciclos son independientes, para determinar el número de repeticiones que ejecutará el algoritmo construimos el cálculo de adentro hacia afuera: (i) sabemos que el ciclo $k$ ejecutará $n$ repeticiones; (ii) por tanto el ciclo $j$ ejecutará $n$ veces las $n$ repeticiones del ciclo $k$; y finalmente (iii) el ciclo $i$ ejecutará $n$ veces las $n \cdot n$ repeticiones del ciclo $j$.

Otra manera de entender este comportamiento es formalizándolo como una serie de sumatorias.

$$
\sum_{i=1}^{n} \sum_{j=1}^{n} \sum_{k=1}^{n} 1 =
\sum_{i=1}^{n} \sum_{j=1}^{n} n =
\sum_{i=1}^{n} n \cdot \sum_{j=1}^{n} 1 =
\sum_{i=1}^{n} n \cdot n =
$$

De ambas formas obtenemos entonces que

$$
T(n) = n \cdot n \cdot n = \mathcal{O}(n^3)
$$

De esta forma, podemos concluir que cuando tenemos ciclos anidados que __son independientes entre sí__ podemos calcuilar su número de repeticiones multiplicando el número de repeticiones del ciclo más interno por el número de repeticiones del ciclo que lo contiene.